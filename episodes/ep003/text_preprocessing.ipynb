{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac04ec7e-cc6c-465d-9f4d-e12caa5f8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ebooklib\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f0599b-4321-47fa-a6ff-8f555426dc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/vdsukhov/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/vdsukhov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/vdsukhov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "860f9ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vdsukhov/mambaforge/envs/wc/lib/python3.10/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n",
      "/home/vdsukhov/mambaforge/envs/wc/lib/python3.10/site-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
     ]
    }
   ],
   "source": [
    "eb = epub.read_epub('./data/dune_book.epub') # speicify path for your book here\n",
    "items = list(eb.get_items_of_type(ebooklib.ITEM_DOCUMENT))\n",
    "items = [item for item in items if 'chapter' in item.get_name()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc367453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A beginning is the time for taking the most delicate care that the balances are correct. This every \n"
     ]
    }
   ],
   "source": [
    "buffer = []\n",
    "for it in items:\n",
    "    sp = bs(it.get_body_content(), 'html.parser')\n",
    "    text = \" \".join([p.get_text() for p in sp.find_all('p')])\n",
    "    buffer.append(text)\n",
    "\n",
    "dune = \" \".join(buffer)\n",
    "print(dune[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d317a842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A beginning is the time for taking the most delicate care that the balances are correct This every s\n"
     ]
    }
   ],
   "source": [
    "dune = dune.split()\n",
    "dune = \" \".join([re.sub(r'\\W+', '', w) for w in dune])\n",
    "print(dune[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08589094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 'DT'), ('beginning', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('time', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(dune)\n",
    "tokens = pos_tag([t.lower() for t in tokens])\n",
    "print(tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f87a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'beginning', 'be', 'the', 'time']\n"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "lemmas = [wnl.lemmatize(token, pos=tag[0].lower()) if tag[0].lower() in ['a', 'n', 'v'] else wnl.lemmatize(token) for token, tag in tokens]\n",
    "print(lemmas[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f4ac341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BEGINNING', 'TIME', 'TAKE', 'DELICATE', 'CARE']\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmas = [l.upper() for l in lemmas if l not in stop_words]\n",
    "print(lemmas[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f079933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAY</td>\n",
       "      <td>2463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAUL</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JESSICA</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THINK</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ONE</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNOW</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BARON</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SEE</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DUKE</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COULD</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  freq\n",
       "0      SAY  2463\n",
       "1     PAUL  1652\n",
       "2  JESSICA   845\n",
       "3    THINK   755\n",
       "4      ONE   633\n",
       "5     KNOW   620\n",
       "6    BARON   568\n",
       "7      SEE   562\n",
       "8     DUKE   560\n",
       "9    COULD   511"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqd = {w: lemmas.count(w) for w in set(lemmas)}\n",
    "df = pd.DataFrame({'word': freqd.keys(), 'freq': freqd.values()})\n",
    "df = df.sort_values(by='freq', ascending=False, ignore_index=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d0e2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/dune_words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4106717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
